"""
1é€±é–“ãƒ‡ãƒ¼ã‚¿ä¿æŒã‚·ã‚¹ãƒ†ãƒ 
ç›´è¿‘7æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä¿æŒã—ã€å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•å‰Šé™¤
"""

import os
import json
from datetime import datetime, timedelta
import glob

class WeeklyDataManager:
    """1é€±é–“ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, data_directory=None):
        # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
        self.data_dir = data_directory if data_directory else os.path.dirname(os.path.abspath(__file__))
        
        # ç®¡ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.file_patterns = {
            'prediction_files': 'äºˆæƒ³ãƒ‡ãƒ¼ã‚¿_*.json',
            'race_files': 'ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿_*.json',
            'weather_files': 'å¤©æ°—ãƒ‡ãƒ¼ã‚¿_*.json',
            'verification_files': 'æ¤œè¨¼çµæœ_*.json',
            'learning_files': 'å­¦ç¿’ãƒ¬ãƒãƒ¼ãƒˆ_*.json',
            'note_articles': 'noteè¨˜äº‹_*.md',
            'twitter_posts': 'XæŠ•ç¨¿æ–‡_*.json'
        }
        
        # ä¿æŒæœŸé–“ï¼ˆæ—¥ï¼‰
        self.retention_days = 7
        
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
        self.log_file = os.path.join(self.data_dir, "ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒ­ã‚°.json")
    
    def clean_old_files(self):
        """å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤"""
        
        cutoff_date = datetime.now() - timedelta(days=self.retention_days)
        deleted_files = []
        protected_files = []
        
        print(f"ğŸ§¹ {self.retention_days}æ—¥ã‚ˆã‚Šå¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ä¸­...")
        print(f"åŸºæº–æ—¥æ™‚: {cutoff_date.strftime('%Y-%m-%d %H:%M:%S')}")
        
        for file_type, pattern in self.file_patterns.items():
            file_path = os.path.join(self.data_dir, pattern)
            matching_files = glob.glob(file_path)
            
            for file_path in matching_files:
                try:
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ—¥ä»˜ã‚’æŠ½å‡º
                    file_date = self._extract_date_from_filename(file_path)
                    
                    if file_date and file_date < cutoff_date.date():
                        # ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å®Ÿè¡Œ
                        if self._is_safe_to_delete(file_path):
                            os.remove(file_path)
                            deleted_files.append({
                                'file_path': file_path,
                                'file_date': file_date.isoformat(),
                                'file_type': file_type,
                                'deleted_at': datetime.now().isoformat()
                            })
                            print(f"ğŸ—‘ï¸ å‰Šé™¤: {os.path.basename(file_path)}")
                        else:
                            protected_files.append(file_path)
                            print(f"ğŸ”’ ä¿è­·: {os.path.basename(file_path)}")
                    
                except Exception as e:
                    print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
        
        # å‰Šé™¤çµæœã‚’ãƒ­ã‚°ã«è¨˜éŒ²
        deletion_log = {
            'deletion_date': datetime.now().isoformat(),
            'cutoff_date': cutoff_date.isoformat(),
            'deleted_files': deleted_files,
            'protected_files': protected_files,
            'total_deleted': len(deleted_files)
        }
        
        self._save_deletion_log(deletion_log)
        
        print(f"âœ… ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: {len(deleted_files)}ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤")
        return deletion_log
    
    def _extract_date_from_filename(self, file_path):
        """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡º"""
        
        filename = os.path.basename(file_path)
        
        # YYYYMMDDå½¢å¼ã®æ—¥ä»˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
        import re
        date_pattern = r'(\d{8})'
        match = re.search(date_pattern, filename)
        
        if match:
            date_str = match.group(1)
            try:
                return datetime.strptime(date_str, '%Y%m%d').date()
            except ValueError:
                return None
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°æ—¥æ™‚ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦ä½¿ç”¨
        try:
            file_mtime = os.path.getmtime(file_path)
            return datetime.fromtimestamp(file_mtime).date()
        except:
            return None
    
    def _is_safe_to_delete(self, file_path):
        """ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã®å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯"""
        
        filename = os.path.basename(file_path)
        
        # å‰Šé™¤ç¦æ­¢ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³
        protected_patterns = [
            'ã‚·ã‚¹ãƒ†ãƒ ',
            'config',
            'setting',
            'template',
            'è¨­å®š',
            'ãƒ­ã‚°'
        ]
        
        for pattern in protected_patterns:
            if pattern in filename.lower():
                return False
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆç©ºãƒ•ã‚¡ã‚¤ãƒ«ã¯å‰Šé™¤OKï¼‰
        try:
            file_size = os.path.getsize(file_path)
            return file_size >= 0  # å¸¸ã«Trueï¼ˆã‚µã‚¤ã‚ºåˆ¶é™ãªã—ï¼‰
        except:
            return False
    
    def get_current_data_status(self):
        """ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿çŠ¶æ³ã‚’å–å¾—"""
        
        status = {
            'scan_date': datetime.now().isoformat(),
            'data_directory': self.data_dir,
            'retention_days': self.retention_days,
            'file_counts': {},
            'oldest_file': None,
            'newest_file': None,
            'total_files': 0,
            'total_size': 0
        }
        
        all_files = []
        
        # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã‚’ã‚¹ã‚­ãƒ£ãƒ³
        for file_type, pattern in self.file_patterns.items():
            file_path = os.path.join(self.data_dir, pattern)
            matching_files = glob.glob(file_path)
            
            file_info = []
            total_size = 0
            
            for file_path in matching_files:
                try:
                    file_stat = os.stat(file_path)
                    file_date = self._extract_date_from_filename(file_path)
                    
                    file_details = {
                        'path': file_path,
                        'name': os.path.basename(file_path),
                        'size': file_stat.st_size,
                        'modified': datetime.fromtimestamp(file_stat.st_mtime).isoformat(),
                        'extracted_date': file_date.isoformat() if file_date else None
                    }
                    
                    file_info.append(file_details)
                    total_size += file_stat.st_size
                    all_files.append(file_details)
                    
                except Exception as e:
                    print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
            
            status['file_counts'][file_type] = {
                'count': len(file_info),
                'total_size': total_size,
                'files': file_info
            }
        
        # å…¨ä½“çµ±è¨ˆ
        if all_files:
            status['total_files'] = len(all_files)
            status['total_size'] = sum(f['size'] for f in all_files)
            
            # æœ€å¤ãƒ»æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«
            sorted_files = sorted(all_files, key=lambda x: x['modified'])
            status['oldest_file'] = sorted_files[0]['name']
            status['newest_file'] = sorted_files[-1]['name']
        
        return status
    
    def _save_deletion_log(self, deletion_log):
        """å‰Šé™¤ãƒ­ã‚°ã‚’ä¿å­˜"""
        
        try:
            # æ—¢å­˜ãƒ­ã‚°ã‚’èª­ã¿è¾¼ã¿
            logs = []
            if os.path.exists(self.log_file):
                with open(self.log_file, 'r', encoding='utf-8') as f:
                    logs = json.load(f)
            
            # æ–°ã—ã„ãƒ­ã‚°ã‚’è¿½åŠ 
            logs.append(deletion_log)
            
            # å¤ã„ãƒ­ã‚°ã‚‚7æ—¥ã§å‰Šé™¤ï¼ˆãƒ­ã‚°ã®ãƒ­ã‚°ï¼‰
            cutoff = datetime.now() - timedelta(days=self.retention_days)
            logs = [log for log in logs 
                   if datetime.fromisoformat(log['deletion_date']) > cutoff]
            
            # ãƒ­ã‚°ä¿å­˜
            with open(self.log_file, 'w', encoding='utf-8') as f:
                json.dump(logs, f, ensure_ascii=False, indent=2)
            
        except Exception as e:
            print(f"âš ï¸ ãƒ­ã‚°ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def schedule_daily_cleanup(self):
        """æ¯æ—¥ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°"""
        
        print("ğŸ“… æ¯æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œ...")
        
        # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿çŠ¶æ³ç¢ºèª
        before_status = self.get_current_data_status()
        print(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‰: {before_status['total_files']}ãƒ•ã‚¡ã‚¤ãƒ«")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å®Ÿè¡Œ
        deletion_result = self.clean_old_files()
        
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¾Œã®çŠ¶æ³ç¢ºèª
        after_status = self.get_current_data_status()
        print(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¾Œ: {after_status['total_files']}ãƒ•ã‚¡ã‚¤ãƒ«")
        
        # ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        summary = {
            'cleanup_date': datetime.now().isoformat(),
            'before_count': before_status['total_files'],
            'after_count': after_status['total_files'],
            'deleted_count': deletion_result['total_deleted'],
            'space_freed': before_status['total_size'] - after_status['total_size']
        }
        
        print(f"ğŸ“Š å‰Šé™¤ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {summary['deleted_count']}")
        print(f"ğŸ’¾ è§£æ”¾å®¹é‡: {summary['space_freed']:,} bytes")
        
        return summary
    
    def manual_file_removal(self, file_pattern):
        """æ‰‹å‹•ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ï¼ˆç‰¹å®šãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰"""
        
        print(f"ğŸ¯ æ‰‹å‹•å‰Šé™¤ãƒ¢ãƒ¼ãƒ‰: {file_pattern}")
        
        file_path = os.path.join(self.data_dir, file_pattern)
        matching_files = glob.glob(file_path)
        
        if not matching_files:
            print("è©²å½“ãƒ•ã‚¡ã‚¤ãƒ«ãªã—")
            return []
        
        deleted_files = []
        
        for file_path in matching_files:
            try:
                filename = os.path.basename(file_path)
                
                # ç¢ºèªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå®Ÿéš›ã®é‹ç”¨ã§ã¯å‰Šé™¤ï¼‰
                print(f"å‰Šé™¤å¯¾è±¡: {filename}")
                
                if self._is_safe_to_delete(file_path):
                    os.remove(file_path)
                    deleted_files.append(filename)
                    print(f"âœ… å‰Šé™¤å®Œäº†: {filename}")
                else:
                    print(f"ğŸ”’ å‰Šé™¤ä¿è­·: {filename}")
                    
            except Exception as e:
                print(f"âŒ å‰Šé™¤ã‚¨ãƒ©ãƒ¼ {filename}: {e}")
        
        print(f"æ‰‹å‹•å‰Šé™¤å®Œäº†: {len(deleted_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
        return deleted_files
    
    def get_file_age_distribution(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«å¹´é½¢åˆ†å¸ƒå–å¾—"""
        
        distribution = {
            '0-1æ—¥': 0,
            '1-3æ—¥': 0,
            '3-7æ—¥': 0,
            '7æ—¥ä»¥ä¸Š': 0
        }
        
        now = datetime.now()
        
        for file_type, pattern in self.file_patterns.items():
            file_path = os.path.join(self.data_dir, pattern)
            matching_files = glob.glob(file_path)
            
            for file_path in matching_files:
                try:
                    file_date = self._extract_date_from_filename(file_path)
                    if file_date:
                        age = (now.date() - file_date).days
                        
                        if age <= 1:
                            distribution['0-1æ—¥'] += 1
                        elif age <= 3:
                            distribution['1-3æ—¥'] += 1
                        elif age <= 7:
                            distribution['3-7æ—¥'] += 1
                        else:
                            distribution['7æ—¥ä»¥ä¸Š'] += 1
                
                except Exception as e:
                    continue
        
        return distribution

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œç”¨
if __name__ == "__main__":
    print("ğŸ—‚ï¸ ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    test_dir = os.path.dirname(os.path.abspath(__file__))
    manager = WeeklyDataManager(test_dir)
    
    # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿çŠ¶æ³
    print("\nğŸ“Š ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿çŠ¶æ³:")
    status = manager.get_current_data_status()
    print(f"ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {status['total_files']}")
    print(f"ç·ã‚µã‚¤ã‚º: {status['total_size']:,} bytes")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«å¹´é½¢åˆ†å¸ƒ
    print("\nğŸ“… ãƒ•ã‚¡ã‚¤ãƒ«å¹´é½¢åˆ†å¸ƒ:")
    distribution = manager.get_file_age_distribution()
    for age_range, count in distribution.items():
        print(f"- {age_range}: {count}ãƒ•ã‚¡ã‚¤ãƒ«")
    
    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œï¼ˆãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼‰
    print("\nğŸ§¹ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆ:")
    # cleanup_result = manager.schedule_daily_cleanup()
    print("ï¼ˆå®Ÿéš›ã®å‰Šé™¤ã¯å®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ï¼‰")
    
    print("\nâœ… ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Œäº†")
"""
ãƒªãƒ³ã‚¯ã¨HTMLã‚¿ã‚°ã®SEOæœ€é©åŒ–çŠ¶æ³ã‚’åŒ…æ‹¬çš„ã«åˆ†æ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.wordpress_api import WordPressBlogAutomator
import requests
import re

def analyze_link_and_tag_seo(post_id):
    """ãƒªãƒ³ã‚¯ã¨ã‚¿ã‚°ã®SEOæœ€é©åŒ–çŠ¶æ³ã‚’è©³ç´°åˆ†æ"""
    
    wp = WordPressBlogAutomator()  # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è‡ªå‹•èª­ã¿è¾¼ã¿
    
    response = requests.get(f'{wp.api_url}/posts/{post_id}', headers=wp.headers)
    if response.status_code != 200:
        return None
        
    post = response.json()
    title = post['title']['rendered']
    content = post['content']['rendered']
    
    print(f'ğŸ” ãƒªãƒ³ã‚¯ãƒ»ã‚¿ã‚°SEOåˆ†æ: {title[:50]}...')
    print('='*80)
    
    # 1. ãƒªãƒ³ã‚¯ã®ã‚¢ãƒ³ã‚«ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ
    print('ğŸ”— ãƒªãƒ³ã‚¯ã®SEOæœ€é©åŒ–çŠ¶æ³:')
    
    # å†…éƒ¨ãƒªãƒ³ã‚¯ã®ã‚¢ãƒ³ã‚«ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ
    internal_links = re.findall(r'<a[^>]*href=["\']https://muffin-blog\.com[^"\']*["\']*[^>]*>(.*?)</a>', content, re.DOTALL)
    print(f'   å†…éƒ¨ãƒªãƒ³ã‚¯ç·æ•°: {len(internal_links)}å€‹')
    
    if internal_links:
        print('   å†…éƒ¨ãƒªãƒ³ã‚¯ã‚¢ãƒ³ã‚«ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ:')
        keyword_internal_count = 0
        for i, anchor in enumerate(internal_links[:5]):
            clean_anchor = re.sub(r'<[^>]+>', '', anchor).strip()
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å«æœ‰ãƒã‚§ãƒƒã‚¯
            has_keyword = any(kw in clean_anchor for kw in ['Audible', 'ãŠé‡‘', 'æŠ•è³‡', 'ç¯€ç´„', 'å§‹ã‚æ–¹'])
            if has_keyword:
                keyword_internal_count += 1
            keyword_status = 'âœ…' if has_keyword else 'âŒ'
            print(f'     {i+1}. "{clean_anchor}" {keyword_status}')
        
        if internal_links:
            keyword_internal_ratio = keyword_internal_count / min(len(internal_links), 5) * 100
            print(f'   å†…éƒ¨ãƒªãƒ³ã‚¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å«æœ‰ç‡: {keyword_internal_ratio:.1f}% (æ¨å¥¨: 80%ä»¥ä¸Š)')
    
    # å¤–éƒ¨ãƒªãƒ³ã‚¯ã®ã‚¢ãƒ³ã‚«ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ
    external_links = re.findall(r'<a[^>]*href=["\']https?://(?!muffin-blog\.com)[^"\']*["\']*[^>]*>(.*?)</a>', content, re.DOTALL)
    print(f'   å¤–éƒ¨ãƒªãƒ³ã‚¯ç·æ•°: {len(external_links)}å€‹')
    
    if external_links:
        print('   å¤–éƒ¨ãƒªãƒ³ã‚¯ã‚¢ãƒ³ã‚«ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ:')
        generic_anchors = 0
        for i, anchor in enumerate(external_links[:5]):
            clean_anchor = re.sub(r'<[^>]+>', '', anchor).strip()
            # æ±ç”¨çš„ãªã‚¢ãƒ³ã‚«ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆãƒã‚§ãƒƒã‚¯
            is_generic = clean_anchor in ['ã“ã¡ã‚‰', 'ã“ã“', 'ã‚¯ãƒªãƒƒã‚¯', 'ãƒªãƒ³ã‚¯', 'è©³ç´°', 'å…¬å¼ã‚µã‚¤ãƒˆ']
            if is_generic:
                generic_anchors += 1
            generic_status = 'âŒ æ±ç”¨çš„' if is_generic else 'âœ… å…·ä½“çš„'
            print(f'     {i+1}. "{clean_anchor}" {generic_status}')
        
        if external_links:
            generic_ratio = generic_anchors / min(len(external_links), 5) * 100
            print(f'   æ±ç”¨çš„ã‚¢ãƒ³ã‚«ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆç‡: {generic_ratio:.1f}% (æ¨å¥¨: 0%)')
    
    # 2. ãƒªãƒ³ã‚¯ã®relå±æ€§åˆ†æ
    print(f'\nğŸ·ï¸ ãƒªãƒ³ã‚¯å±æ€§ã®SEOæœ€é©åŒ–:')
    
    # nofollowå±æ€§ã®åˆ†æ
    nofollow_links = len(re.findall(r'rel=["\'][^"\']*nofollow[^"\']*["\']', content))
    external_links_count = len(re.findall(r'href=["\']https?://(?!muffin-blog\.com)', content))
    
    print(f'   nofollowè¨­å®šæ¸ˆã¿ãƒªãƒ³ã‚¯: {nofollow_links}å€‹')
    if external_links_count > 0:
        nofollow_ratio = nofollow_links / external_links_count * 100
        print(f'   å¤–éƒ¨ãƒªãƒ³ã‚¯nofollowç‡: {nofollow_ratio:.1f}%')
    
    # target='_blank'ã®åˆ†æ
    blank_links = len(re.findall(r'target=["\']_blank["\']', content))
    print(f'   æ–°ã—ã„ã‚¿ãƒ–ã§é–‹ããƒªãƒ³ã‚¯: {blank_links}å€‹')
    
    # sponsoredå±æ€§ã®åˆ†æï¼ˆã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆãƒªãƒ³ã‚¯ç”¨ï¼‰
    sponsored_links = len(re.findall(r'rel=["\'][^"\']*sponsored[^"\']*["\']', content))
    amazon_links = len(re.findall(r'amazon\.|amzn\.', content))
    print(f'   sponsoredå±æ€§è¨­å®š: {sponsored_links}å€‹')
    print(f'   Amazonãƒªãƒ³ã‚¯æ•°: {amazon_links}å€‹')
    
    if amazon_links > 0 and sponsored_links == 0:
        print('   âš ï¸ Amazonãƒªãƒ³ã‚¯ã«sponsoredå±æ€§æœªè¨­å®šï¼ˆGoogleæ¨å¥¨é•åï¼‰')
    
    # 3. ç”»åƒã®altå±æ€§ã¨SEOæœ€é©åŒ–
    print(f'\nğŸ–¼ï¸ ç”»åƒã‚¿ã‚°ã®SEOæœ€é©åŒ–:')
    
    images = re.findall(r'<img[^>]*>', content)
    alt_texts = re.findall(r'alt=["\']([^"\']*)["\']', content)
    title_attrs = re.findall(r'<img[^>]*title=["\']([^"\']*)["\'][^>]*>', content)
    
    print(f'   ç”»åƒç·æ•°: {len(images)}å€‹')
    print(f'   altå±æ€§è¨­å®š: {len(alt_texts)}å€‹ ({len(alt_texts)/len(images)*100 if images else 0:.1f}%)')
    print(f'   titleå±æ€§è¨­å®š: {len(title_attrs)}å€‹')
    
    # altå±æ€§ã®SEOå“è³ªåˆ†æ
    if alt_texts:
        keyword_alts = 0
        descriptive_alts = 0
        empty_alts = 0
        
        print('   altå±æ€§ã®å“è³ªåˆ†æ:')
        for i, alt in enumerate(alt_texts[:5]):
            if not alt.strip():
                empty_alts += 1
                continue
                
            has_keyword = any(kw in alt for kw in ['Audible', 'ãŠé‡‘', 'æŠ•è³‡', 'ç¯€ç´„'])
            is_descriptive = len(alt) > 10 and alt not in ['ç”»åƒ', 'image', 'img']
            
            if has_keyword:
                keyword_alts += 1
            if is_descriptive:
                descriptive_alts += 1
                
            keyword_status = 'âœ…' if has_keyword else 'âŒ'
            descriptive_status = 'âœ…' if is_descriptive else 'âŒ'
            print(f'     {i+1}. "{alt}" ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:{keyword_status} èª¬æ˜çš„:{descriptive_status}')
        
        total_analyzed = min(len(alt_texts), 5)
        keyword_alt_ratio = keyword_alts / total_analyzed * 100 if total_analyzed > 0 else 0
        descriptive_ratio = descriptive_alts / total_analyzed * 100 if total_analyzed > 0 else 0
        empty_ratio = empty_alts / len(alt_texts) * 100 if alt_texts else 0
        
        print(f'   ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å«æœ‰ç‡: {keyword_alt_ratio:.1f}% (æ¨å¥¨: 50%ä»¥ä¸Š)')
        print(f'   èª¬æ˜çš„altç‡: {descriptive_ratio:.1f}% (æ¨å¥¨: 90%ä»¥ä¸Š)')
        print(f'   ç©ºã®altç‡: {empty_ratio:.1f}% (æ¨å¥¨: 0%)')
    
    # 4. HTMLã‚¿ã‚°ã®æ„å‘³æ§‹é€ ï¼ˆã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ï¼‰åˆ†æ
    print(f'\nğŸ“ HTMLã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ§‹é€ :')
    
    # å¼·èª¿ã‚¿ã‚°ã®ä½¿ç”¨çŠ¶æ³
    strong_tags = re.findall(r'<strong[^>]*>(.*?)</strong>', content, re.DOTALL)
    em_tags = re.findall(r'<em[^>]*>(.*?)</em>', content, re.DOTALL)
    b_tags = re.findall(r'<b[^>]*>(.*?)</b>', content, re.DOTALL)
    i_tags = re.findall(r'<i[^>]*>(.*?)</i>', content, re.DOTALL)
    
    print(f'   <strong>ã‚¿ã‚°: {len(strong_tags)}å€‹ (SEOæ¨å¥¨)')
    print(f'   <em>ã‚¿ã‚°: {len(em_tags)}å€‹ (SEOæ¨å¥¨)')
    print(f'   <b>ã‚¿ã‚°: {len(b_tags)}å€‹ (éæ¨å¥¨)')
    print(f'   <i>ã‚¿ã‚°: {len(i_tags)}å€‹ (éæ¨å¥¨)')
    
    if len(b_tags) > 0 or len(i_tags) > 0:
        print('   âš ï¸ <b><i>ã‚¿ã‚°ã®ä»£ã‚ã‚Šã«<strong><em>ã‚¿ã‚°ä½¿ç”¨ã‚’æ¨å¥¨')
    
    # å¼·èª¿ã‚¿ã‚°å†…ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
    if strong_tags:
        keyword_strong = sum(1 for strong in strong_tags if any(kw in re.sub(r'<[^>]+>', '', strong) for kw in ['Audible', 'ãŠé‡‘', 'æŠ•è³‡']))
        keyword_strong_ratio = keyword_strong / len(strong_tags) * 100
        print(f'   å¼·èª¿ã‚¿ã‚°å†…ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç‡: {keyword_strong_ratio:.1f}% (æ¨å¥¨: 30%ä»¥ä¸Š)')
    
    # 5. ãƒªã‚¹ãƒˆæ§‹é€ ã®æœ€é©åŒ–
    print(f'\nğŸ“‹ ãƒªã‚¹ãƒˆæ§‹é€ ã®æœ€é©åŒ–:')
    
    ul_tags = re.findall(r'<ul[^>]*>', content)
    ol_tags = re.findall(r'<ol[^>]*>', content)
    li_tags = re.findall(r'<li[^>]*>', content)
    
    print(f'   ç®‡æ¡æ›¸ããƒªã‚¹ãƒˆ: {len(ul_tags)}å€‹')
    print(f'   ç•ªå·ä»˜ããƒªã‚¹ãƒˆ: {len(ol_tags)}å€‹')
    print(f'   ãƒªã‚¹ãƒˆé …ç›®ç·æ•°: {len(li_tags)}å€‹')
    
    if len(ul_tags) + len(ol_tags) == 0:
        print('   âš ï¸ ãƒªã‚¹ãƒˆæ§‹é€ æœªä½¿ç”¨ï¼ˆèª­ã¿ã‚„ã™ã•ã¨SEOã«ä¸åˆ©ï¼‰')
    
    # 6. ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã®æœ€é©åŒ–
    table_tags = re.findall(r'<table[^>]*>', content)
    th_tags = re.findall(r'<th[^>]*>', content)
    td_tags = re.findall(r'<td[^>]*>', content)
    
    print(f'\nğŸ“Š ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ :')
    print(f'   ãƒ†ãƒ¼ãƒ–ãƒ«æ•°: {len(table_tags)}å€‹')
    print(f'   ãƒ˜ãƒƒãƒ€ãƒ¼ã‚»ãƒ«æ•°: {len(th_tags)}å€‹')
    print(f'   ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ«æ•°: {len(td_tags)}å€‹')
    
    if len(table_tags) > 0 and len(th_tags) == 0:
        print('   âš ï¸ ãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œï¼ˆ<th>ï¼‰ãŒæœªè¨­å®š')
    
    # 7. æ§‹é€ åŒ–ãƒãƒ¼ã‚¯ã‚¢ãƒƒãƒ—ã®ç¢ºèª
    print(f'\nğŸ—ï¸ æ§‹é€ åŒ–ãƒãƒ¼ã‚¯ã‚¢ãƒƒãƒ—:')
    
    # Schema.orgæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿
    json_ld = re.findall(r'<script[^>]*type=["\']application/ld\+json["\'][^>]*>(.*?)</script>', content, re.DOTALL)
    microdata = re.findall(r'itemtype=["\'][^"\']*["\']', content)
    
    print(f'   JSON-LDæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿: {len(json_ld)}å€‹')
    print(f'   Microdataå±æ€§: {len(microdata)}å€‹')
    
    if len(json_ld) == 0 and len(microdata) == 0:
        print('   âš ï¸ æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿æœªå®Ÿè£…ï¼ˆãƒªãƒƒãƒã‚¹ãƒ‹ãƒšãƒƒãƒˆè¡¨ç¤ºä¸å¯ï¼‰')
    
    # 8. ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ã¨SEO
    print(f'\nâ™¿ ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£é–¢é€£:')
    
    # ariaå±æ€§ã®ä½¿ç”¨
    aria_labels = re.findall(r'aria-label=["\'][^"\']*["\']', content)
    aria_described = re.findall(r'aria-describedby=["\'][^"\']*["\']', content)
    
    print(f'   aria-labelå±æ€§: {len(aria_labels)}å€‹')
    print(f'   aria-describedbyå±æ€§: {len(aria_described)}å€‹')
    
    return True

if __name__ == "__main__":
    print('ğŸš€ å…¨è¨˜äº‹ã®ãƒªãƒ³ã‚¯ãƒ»ã‚¿ã‚°SEOæœ€é©åŒ–çŠ¶æ³åˆ†æ')
    print('='*80)
    
    target_posts = [2732, 2677, 2625, 2535, 2210, 649]
    
    for post_id in target_posts:
        analyze_link_and_tag_seo(post_id)
        print('\n' + '='*80 + '\n')
    
    print('ğŸ“‹ åˆ†æå®Œäº†: ãƒªãƒ³ã‚¯ã¨ã‚¿ã‚°ã®æœ€é©åŒ–çŠ¶æ³ã‚’ç¢ºèªã—ã¾ã—ãŸ')